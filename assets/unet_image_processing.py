# -*- coding: utf-8 -*-
"""FinalProject.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16HofvuHZPPpFvpyvT-pWtuEehVNJaoKn
"""

from google.colab import drive
drive.mount('/content/gdrive')

import numpy as np
npzfile = np.load('./gdrive/MyDrive/X_and_y.npz')
npztest = np.load('./gdrive/MyDrive/test_images.npz')
X = npzfile['X']
y = npzfile['y']

y_test = npztest['X']

import matplotlib.pyplot as plt
idx = 7
plt.imshow(y_test[0]/255, cmap = 'gray')


plt.figure()
plt.imshow(y_test[0]/255)

import sklearn as sk
import sklearn.model_selection

X_train, X_val, y_train, y_val = sk.model_selection.train_test_split(X, y, random_state = 123)

import tensorflow as tf
data_train = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(16)
data_val = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(16)

type(data_train)
print(data_train[0])

for img, mask in data_val:
  print(img.shape)
  print(mask.shape)
  break

print (mask)

import matplotlib.pyplot as plt
plt.imshow(img[0]/255 + .5*mask[0], cmap = 'gray') #mask superimposed on the image
plt.figure()
plt.imshow(mask[0]) #without superimposing

inputs = tf.keras.Input(shape=(128,128,1))

# Downsample + Maxpooling - 64 filters
a = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same')(inputs)
print(a.shape)
a_ = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same')(a)
print(a_.shape)
a = tf.keras.layers.MaxPool2D(pool_size=(2,2))(a_)
print(a.shape)

# Downsample + Maxpooling - 128 filters
b = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same')(a)
b_ = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same')(b)
b = tf.keras.layers.MaxPool2D(pool_size=(2,2))(b_)
print(b_.shape)
print(b.shape)

# Downsample + Maxpooling - 256 filters
c = tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding='same')(b)
c_ = tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding='same')(c)
c = tf.keras.layers.MaxPool2D(pool_size=(2,2))(c_)
print(c_.shape)
print(c.shape)

# Downsample + Maxpooling - 512 filters
d = tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3), activation='relu', padding='same')(c)
d_ = tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3), activation='relu', padding='same')(d)
d = tf.keras.layers.MaxPool2D(pool_size=(2,2))(d_)
print(d_.shape)
print(d.shape)

# Downsample - 1024 filters
e = tf.keras.layers.Conv2D(filters=1024, kernel_size=(3,3), activation='relu', padding='same')(d)
e = tf.keras.layers.Conv2D(filters=1024, kernel_size=(3,3), activation='relu', padding='same')(e)
print(e.shape)

# Upsampling + Convolution + Concatenation + Convolution - 512 filters
dU = tf.keras.layers.UpSampling2D(size=(2,2))(e)
#print(e.shape)
dU = tf.keras.layers.Conv2D(filters = 512, kernel_size=(2,2), activation='relu', padding='same')(dU)
print(dU.shape)
dU = tf.keras.layers.concatenate([dU, d_])
print(dU.shape)
dU = tf.keras.layers.Conv2D(filters = 512, kernel_size=(3,3), activation='relu', padding='same')(dU)
dU = tf.keras.layers.Conv2D(filters = 512, kernel_size=(3,3), activation='relu', padding='same')(dU)
print(dU.shape)

# Upsampling + Convolution + Concatenation + Convolution - 256 filters
cU = tf.keras.layers.UpSampling2D(size=(2,2))(dU)
print(cU.shape)
cU = tf.keras.layers.Conv2D(filters = 256, kernel_size=(2,2), activation='relu', padding='same')(cU)
cU = tf.keras.layers.concatenate([cU, c_])
print(cU.shape)
cU = tf.keras.layers.Conv2D(filters = 256, kernel_size=(3,3), activation='relu', padding='same')(cU)
cU = tf.keras.layers.Conv2D(filters = 256, kernel_size=(3,3), activation='relu', padding='same')(cU)
print(cU.shape)

# Upsampling + Convolution + Concatenation + Convolution - 128 filters
bU = tf.keras.layers.UpSampling2D(size=(2,2))(cU)
print(bU.shape)
bU = tf.keras.layers.Conv2D(filters = 128, kernel_size=(2,2), activation='relu', padding='same')(bU)
bU = tf.keras.layers.concatenate([bU, b_])
bU = tf.keras.layers.Conv2D(filters = 128, kernel_size=(3,3), activation='relu', padding='same')(bU)
bU = tf.keras.layers.Conv2D(filters = 128, kernel_size=(3,3), activation='relu', padding='same')(bU)
bU.shape

# Upsampling + Convolution + Concatenation + Convolution - 64 filters
aU = tf.keras.layers.UpSampling2D(size=(2,2))(bU)
print(aU.shape)
aU = tf.keras.layers.Conv2D(filters = 64, kernel_size=(2,2), activation='relu', padding='same')(aU)
print(a_.shape)
aU = tf.keras.layers.concatenate([aU, a_])
aU = tf.keras.layers.Conv2D(filters = 64, kernel_size=(3,3), activation='relu', padding='same')(aU)
aU = tf.keras.layers.Conv2D(filters = 64, kernel_size=(3,3), activation='relu', padding='same')(aU)
aU.shape

#x = tf.keras.layers.Conv2D(filters=32, kernel_size=(2,2), activation='relu', padding='same')(x)
outputs = tf.keras.layers.Conv2D(filters=1,kernel_size=(1,1), activation='sigmoid', padding='same')(aU)

#outputs = tf.keras.layers.Conv2D(filters=1,kernel_size=(1,1), activation='sigmoid', padding='same')(outputs)
outputs = tf.keras.layers.Dense(units=1, activation='sigmoid')(outputs)
outputs.shape

model = tf.keras.Model(inputs, outputs)

model.summary()

model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])
history = model.fit(data_train, epochs=50, validation_data=data_val)

import matplotlib.pyplot as plt
train_accuracy = history.history['accuracy']
val_accuracy = history.history['val_accuracy']
plt.plot(train_accuracy, label = 'training accuracy')
plt.plot(val_accuracy, label = 'validation_accuracy')
plt.legend()

# take output and round to get hard labels = 1
# cv2 has a function called connectComponents which counts the number of nuclei (one of the outputs of the function gives the count)

count = []
pred_mask = model.predict(y_test)
pred_mask = pred_mask.round()
pred_mask = pred_mask.astype(np.uint8)
import cv2

for idx in range(2000):
  img = pred_mask[idx,:,:,0]
  ret,_ = cv2.connectedComponents(img)
  count.append(ret)

index = []
for i in range(2000):
  index.append(i)

import pandas as pd
kaggle_submission = pd.DataFrame(index, columns = ['index'])
kaggle_submission['count'] = count
fname_submission = 'unet_kaggle_826.csv'
kaggle_submission.to_csv( fname_submission, index = False)
# Image augmentation - data augmentation 
# library called imgaug for data augmentation

import matplotlib.pyplot as plt
idx = 7
plt.imshow(y_test[511]/255, cmap = 'gray')


plt.figure()
plt.imshow(y_test[511]/255 + pred_mask[1700,:,:,0])